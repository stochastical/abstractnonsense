---
title: Structured outputs from LLMs
blog_section:
  - micro-blog
date: "2025-04-14"
description: Structured outputs from LLMs using outlines
link: https://github.com/dottxt-ai/outlines
tags: ["LLM"]
---

This is more of a "to-do" than anything, but I really love the idea of inference-time next-token probability-distribution hacking to enforce structured outputs. There's this neat Python library [outlines](https://github.com/dottxt-ai/outlines) that I'd love to explore in more depth - it even supports context-free grammars for output guiding!
